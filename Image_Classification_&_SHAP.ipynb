{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Image Classification & SHAP\n",
        "\n",
        "This notebook trains 6 different ML algorithms (KNN, MLP, SVM, Naive Bayes, CNN, AlexNet) for both multiclass and binary classification of dementia. Two datasets are used:\n",
        "\n",
        "\n",
        "1.   kaggle dataset - 6400 MRI scans\n",
        "2.   OASIS dataset - 235 MRI scans\n",
        "\n",
        "The kaggle dataset was used to train the algorithms and the OASIS dataset was used to validate results.\n",
        "\n",
        "SHAP, an approach for explaining the output of any machine learning model, was then implemented to determine which regions of the MRI scans were most influential in classification. \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IMVavWiMrlU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Packages"
      ],
      "metadata": {
        "id": "KZRpMKCRFuM8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzqrQsKQw3Cd",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run this to load packages \n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from collections import Counter\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D\n",
        "from keras.layers import Activation, MaxPooling2D, Dropout, Flatten, Reshape\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from numpy import expand_dims\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "import glob\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn import svm\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "import tensorflow.keras as keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D\n",
        "from keras.layers import Activation, MaxPooling2D, Dropout, Flatten, Reshape\n",
        "!pip install -q git+https://github.com/rdk2132/scikeras # workaround for scikeras deprecation\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "!pip install shap\n",
        "\n",
        "\n",
        "def plot_acc(history, ax = None, xlabel = 'Epoch #'):\n",
        "    history = history.history_\n",
        "    history.update({'epoch':list(range(len(history['val_accuracy'])))})\n",
        "    history = pd.DataFrame.from_dict(history)\n",
        "\n",
        "    best_epoch = history.sort_values(by = 'val_accuracy', ascending = False).iloc[0]['epoch']\n",
        "\n",
        "    if not ax:\n",
        "      f, ax = plt.subplots(1,1)\n",
        "    sns.lineplot(x = 'epoch', y = 'val_accuracy', data = history, label = 'Validation', ax = ax)\n",
        "    sns.lineplot(x = 'epoch', y = 'accuracy', data = history, label = 'Training', ax = ax)\n",
        "    ax.axhline(0.5, linestyle = '--',color='red', label = 'Chance')\n",
        "    ax.axvline(x = best_epoch, linestyle = '--', color = 'green', label = 'Best Epoch')  \n",
        "    ax.legend(loc = 7)    \n",
        "    ax.set_ylim([0.4, 1])\n",
        "\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel('Accuracy (Fraction)')\n",
        "    \n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and preparing data - kaggle dataset\n",
        "> https://www.kaggle.com/datasets/sachinkumar413/alzheimer-mri-dataset"
      ],
      "metadata": {
        "id": "9S7LRaCtGMB9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ay_L2VQ8lJ8m"
      },
      "outputs": [],
      "source": [
        "# mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "# downloads kaggle dataset and unzips zip file from drive\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content\"\n",
        "# !kaggle datasets download -d sachinkumar413/alzheimer-mri-dataset\n",
        "file_name = 'drive/MyDrive/Extracurriculars/InspiritAI/Deniz Yilmaz/Data/Old MRI Data/alzheimer-mri-dataset.zip' # once dataset is downloaded in google drive, change the filepath to your filepath\n",
        "with ZipFile(file_name, 'r') as zipfile:\n",
        "    zipfile.extractall()\n",
        "\n",
        "# creates label list and image list\n",
        "label_dirs = glob.glob(\"/content/Dataset/*\")\n",
        "image_list = []\n",
        "\n",
        "# puts images in image_list\n",
        "for label_dir in label_dirs:\n",
        "  label = label_dir.split(\"/\")[3]\n",
        "  for file in glob.glob(label_dir + \"/*.jpg\"):\n",
        "    image = Image.open(file).resize((150,150)) \n",
        "    numpydata = asarray(image)\n",
        "    image_item = np.array([label, file, numpydata])\n",
        "    image_list.append(image_item)\n",
        "\n",
        "# converts image_list to numpy array\n",
        "image_array = np.asarray(image_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUWoxJiE4Zyb"
      },
      "outputs": [],
      "source": [
        "# normalization function\n",
        "def normalize_one_image(image):\n",
        "  return((image - np.min(image)) / (np.max(image) - np.min(image)))\n",
        "\n",
        "# label conversion function\n",
        "def label_to_number(label):\n",
        "  if label == \"Very_Mild_Demented\":\n",
        "    return 1\n",
        "  if label == \"Moderate_Demented\":\n",
        "    return 3\n",
        "  if label == \"Mild_Demented\":\n",
        "    return 2\n",
        "  if label == \"Non_Demented\":\n",
        "    return 0\n",
        "\n",
        "  return -1\n",
        "\n",
        "# converts grayscale to black and white\n",
        "def black_and_white(image):\n",
        "  for i in range(len(image)):\n",
        "    if image[i] > 0.5:\n",
        "      image[i] = 1\n",
        "    if image[i] <= 0.5:\n",
        "      image[i] = 0\n",
        "  return image\n",
        "\n",
        "# creates normalized_image_array and label_array\n",
        "normalized_image_array = []\n",
        "label_array = []\n",
        "\n",
        "# adds normalized images to normalized_image_array and new labels to label_array\n",
        "for item in image_array:\n",
        "  img = item[2]\n",
        "  img = normalize_one_image(img)\n",
        "  img = img.flatten()\n",
        "  # img = black_and_white(img)\n",
        "  label = label_to_number(item[0])\n",
        "  normalized_image_array.append(img)\n",
        "  label_array.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLkZl0ZaUxiT"
      },
      "outputs": [],
      "source": [
        "# converts to binary labels\n",
        "label_binary = label_array.copy()\n",
        "\n",
        "for idx in range(len(label_binary)):\n",
        "  if label_binary[idx] == 3 or label_binary[idx] == 2:\n",
        "    label_binary[idx] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train test validation split"
      ],
      "metadata": {
        "id": "ckE8a5p4GmBq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZG29w8DbYy7"
      },
      "outputs": [],
      "source": [
        "# sets ratios for train, validation, and test\n",
        "train_ratio = 0.7\n",
        "validation_ratio = 0.15\n",
        "test_ratio = 0.15\n",
        "\n",
        "# multiclass\n",
        "X = asarray(normalized_image_array)\n",
        "y = asarray(label_array)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1 - train_ratio, random_state=9)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state=9)\n",
        "\n",
        "# binary\n",
        "y_binary = asarray(label_binary)\n",
        "\n",
        "X_train_binary, X_test_binary, y_train_binary, y_test_binary = train_test_split(X, y_binary, test_size=1 - train_ratio, random_state=9)\n",
        "X_val_binary, X_test_binary, y_val_binary, y_test_binary = train_test_split(X_test_binary, y_test_binary, test_size=test_ratio/(test_ratio + validation_ratio), random_state=9) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training ML models\n",
        "> KNN, MLP, SVM, Naive Bayes, CNN, AlexNet"
      ],
      "metadata": {
        "id": "YkDih4A6HT1C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN multiclass"
      ],
      "metadata": {
        "id": "ugyU2USPHi5i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUMNNV9ZrwSe"
      },
      "outputs": [],
      "source": [
        "# initialize model\n",
        "knn_multiclass = KNeighborsClassifier(n_neighbors=2, weights='distance', metric='euclidean')\n",
        "\n",
        "# train\n",
        "knn_multiclass.fit(X_train, y_train)\n",
        "\n",
        "# predict\n",
        "predictions_knn_multiclass = knn_multiclass.predict(X_val)\n",
        "\n",
        "# model metrics\n",
        "print(\"accuracy score: \", accuracy_score(y_val, predictions_knn_multiclass))\n",
        "print(\"precision score: \", precision_score(y_val, predictions_knn_multiclass, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_val, predictions_knn_multiclass, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_val, predictions_knn_multiclass, average = 'weighted'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQO5sO-h2vtg"
      },
      "outputs": [],
      "source": [
        "# confusion matrix for KNN multiclass\n",
        "\n",
        "confusion = confusion_matrix(y_val, predictions_knn_multiclass)\n",
        "print('Confusion Matrix\\n')\n",
        "print(confusion)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=confusion, display_labels=[\"0\", \"1\", \"2\", \"3\"])\n",
        "disp.plot(cmap='Oranges');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFFlA62HQzxR"
      },
      "outputs": [],
      "source": [
        "# ROC curve for KNN multiclass\n",
        "\n",
        "# compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "n_classes = 4\n",
        "y_score = label_binarize(predictions_knn_multiclass, classes=[0, 1, 2, 3])\n",
        "y_test_bin = label_binarize(y_val, classes=[0, 1, 2, 3])\n",
        "\n",
        "lw = 4\n",
        "\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# compute micro-average ROC curve and ROC area\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_score.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "# first aggregate all false positive rates\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "\n",
        "# then interpolate all ROC curves at this points\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(n_classes):\n",
        "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "# finally average it and compute AUC\n",
        "mean_tpr /= n_classes\n",
        "\n",
        "fpr[\"macro\"] = all_fpr\n",
        "tpr[\"macro\"] = mean_tpr\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "# plot all ROC curves\n",
        "plt.figure()\n",
        "plt.plot(\n",
        "    fpr[\"micro\"],\n",
        "    tpr[\"micro\"],\n",
        "    label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n",
        "    color=\"deeppink\",\n",
        "    linestyle=\":\",\n",
        "    linewidth=4,\n",
        ")\n",
        "\n",
        "plt.plot(\n",
        "    fpr[\"macro\"],\n",
        "    tpr[\"macro\"],\n",
        "    label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n",
        "    color=\"navy\",\n",
        "    linestyle=\":\",\n",
        "    linewidth=4,\n",
        ")\n",
        "\n",
        "colors = [\"aqua\", \"darkorange\", \"cornflowerblue\", \"red\"]\n",
        "for i, color in enumerate(colors):\n",
        "    plt.plot(\n",
        "        fpr[i],\n",
        "        tpr[i],\n",
        "        color=color,\n",
        "        lw=lw,\n",
        "        label=\"ROC curve of class {0} (area = {1:0.2f})\".format(i, roc_auc[i]),\n",
        "    )\n",
        "\n",
        "plt.plot([0, 1], [0, 1], \"k--\", lw=lw)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Some extension of Receiver operating characteristic to multiclass\")\n",
        "plt.legend(bbox_to_anchor=(0, 2), loc='upper left', ncol=1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-PpTeI-yOwx"
      },
      "outputs": [],
      "source": [
        "# KNN multiclass hyperparameter tuning\n",
        "\n",
        "for i in range(10):\n",
        "  # initialize model\n",
        "  knn_multiclass = KNeighborsClassifier(n_neighbors=(i+1), weights='distance', metric='euclidean')\n",
        "\n",
        "  # train\n",
        "  knn_multiclass.fit(X_train, y_train)\n",
        "\n",
        "  # predict\n",
        "  predictions_knn_multiclass = knn_multiclass.predict(X_val)\n",
        "\n",
        "  # model metrics\n",
        "  print(\"KNN Testing Accuracy: neighbors = \", i+1)\n",
        "  print(accuracy_score(y_val, predictions_knn_multiclass))\n",
        "  print(\"precision: \")\n",
        "  print(precision_score(y_val, predictions_knn_multiclass, average = 'weighted'))\n",
        "  print(\"recall: \")\n",
        "  print(recall_score(y_val, predictions_knn_multiclass, average = 'weighted'))\n",
        "  print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP multiclass"
      ],
      "metadata": {
        "id": "earT21BJH2zs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uc1g-6q1BZ8"
      },
      "outputs": [],
      "source": [
        "# initialize model\n",
        "mlp_multiclass = MLPClassifier(hidden_layer_sizes=(10, 5, 4), random_state=1, max_iter= 100)  \n",
        "\n",
        "# train\n",
        "mlp_multiclass.fit(X_train, y_train)\n",
        "\n",
        "# predict\n",
        "predictions_mlp_multiclass = mlp_multiclass.predict(X_val)\n",
        "\n",
        "# model metrics\n",
        "print(\"accuracy score: \", accuracy_score(y_val, predictions_mlp_multiclass))\n",
        "print(\"precision score: \", precision_score(y_val, predictions_mlp_multiclass, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_val, predictions_mlp_multiclass, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_val, predictions_mlp_multiclass, average = 'weighted'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVC multiclass"
      ],
      "metadata": {
        "id": "gYnAKP-PH6lm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-Z_fDWZhOMp1"
      },
      "outputs": [],
      "source": [
        "# experimenting with different kernels\n",
        "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "\n",
        "for kernel_type in kernels:\n",
        "  # initialize model\n",
        "  svc_multiclass = svm.SVC(kernel = kernel_type)\n",
        "\n",
        "  #train\n",
        "  svc_multiclass.fit(X_train, y_train)\n",
        "  \n",
        "  #predict\n",
        "  predictions_svc_multiclass = svc_multiclass.predict(X_val)\n",
        "\n",
        "  # Print the score on the validation data\n",
        "  print(\"SVC model metrics \", kernel_type)\n",
        "  print(\"accuracy score: \", accuracy_score(y_val, predictions_svc_multiclass))\n",
        "  print(\"precision score: \", precision_score(y_val, predictions_svc_multiclass, average = 'weighted'))\n",
        "  print(\"recall score: \", recall_score(y_val, predictions_svc_multiclass, average = 'weighted'))\n",
        "  print(\"f1 score: \", f1_score(y_val, predictions_svc_multiclass, average = 'weighted'))\n",
        "  print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes multiclass"
      ],
      "metadata": {
        "id": "NXpeKFn3H_Z5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kq8psnWKOnKv"
      },
      "outputs": [],
      "source": [
        "# initialize model \n",
        "nb_multiclass = GaussianNB(var_smoothing = 1e-4)\n",
        "\n",
        "# train\n",
        "nb_multiclass.fit(X_train, y_val)\n",
        "\n",
        "# predict\n",
        "predictions_nb_multiclass = nb_multiclass.predict(X_val)\n",
        "\n",
        "print(\"accuracy score: \", accuracy_score(y_val, predictions_nb_multiclass))\n",
        "print(\"precision score: \", precision_score(y_val, predictions_nb_multiclass, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_val, predictions_nb_multiclass, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_val, predictions_nb_multiclass, average = 'weighted'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Multiclass"
      ],
      "metadata": {
        "id": "rqlSCTA6INsN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8hBI19COp7Q"
      },
      "outputs": [],
      "source": [
        "def CNNClassifier(num_classes=4, num_epochs=2, layers=2, dropout=0.25):\n",
        "  def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Reshape((150, 150, 1)))\n",
        "\n",
        "    for i in range(layers):\n",
        "      model.add(Conv2D(150, (3, 3), padding='same'))\n",
        "      model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(150, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(dropout))\n",
        "\n",
        "    # model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "    # model.add(Activation('relu'))\n",
        "    # model.add(Conv2D(64, (3, 3)))\n",
        "    # model.add(Activation('relu'))\n",
        "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    # model.add(Dropout(dropout))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Dense(num_classes))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "  opt = tf.keras.optimizers.legacy.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "  return KerasClassifier(model=create_model, optimizer=opt, \n",
        "                         loss='categorical_crossentropy', epochs=num_epochs, batch_size=10, \n",
        "                         metrics=['accuracy'])\n",
        "\n",
        "cnn_multiclass = CNNClassifier(4, 100, 1, 0.25)\n",
        "history = cnn_multiclass.fit(X=X_train, y=y_train, validation_data=(X_val, y_val))\n",
        "plot_acc(history)\n",
        "\n",
        "predictions_cnn_multiclass = cnn_multiclass.predict(X_val)\n",
        "print(\"accuracy score: \", accuracy_score(y_val, predictions_cnn_multiclass))\n",
        "print(\"precision score: \", precision_score(y_val, predictions_cnn_multiclass, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_val, predictions_cnn_multiclass, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_val, predictions_cnn_multiclass, average = 'weighted'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AlexNet multiclass"
      ],
      "metadata": {
        "id": "_KNNeCICNQUt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DWdY2iKRHHh"
      },
      "outputs": [],
      "source": [
        "def AlexNetClassifier(num_classes=4, num_epochs=2):\n",
        "  def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Reshape((150, 150, 1)))\n",
        "\n",
        "    model.add(Conv2D(96, 11, strides = 3))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(256, 5))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(MaxPooling2D(2))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(384, 3, padding = 'same'))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(MaxPooling2D(2))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(384, 3, padding = 'same'))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(256, 3, padding = 'same'))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(MaxPooling2D(2))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(128))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Dense(4))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "  opt = tf.keras.optimizers.legacy.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "  return KerasClassifier(model=create_model, optimizer=opt, \n",
        "                         loss='categorical_crossentropy', epochs=num_epochs, batch_size=64, \n",
        "                         metrics=['accuracy'])\n",
        "\n",
        "AlexNet_multiclass = AlexNetClassifier(4, 100)\n",
        "history = AlexNet_multiclass.fit(X=X_train, y=y_train, validation_data=(X_val, y_val))\n",
        "plot_acc(history)\n",
        "\n",
        "predictions_AlexNet_multiclass = AlexNet_multiclass.predict(X_val)\n",
        "print(\"accuracy score: \", accuracy_score(y_val, predictions_AlexNet_multiclass))\n",
        "print(\"precision score: \", precision_score(y_val, predictions_AlexNet_multiclass, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_val, predictions_AlexNet_multiclass, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_val, predictions_AlexNet_multiclass, average = 'weighted'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN binary"
      ],
      "metadata": {
        "id": "5QxAEnHRNatW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hG8vGd8GP2F5"
      },
      "outputs": [],
      "source": [
        "# initialize model\n",
        "knn_binary = KNeighborsClassifier(n_neighbors=2, weights='distance', metric='euclidean')\n",
        "\n",
        "# train\n",
        "knn_binary.fit(X_train_binary, y_train_binary)\n",
        "\n",
        "# predict\n",
        "predictions_knn_binary = knn_binary.predict(X_val_binary)\n",
        "\n",
        "# model metrics\n",
        "print(\"accuracy score: \", accuracy_score(y_val_binary, predictions_knn_binary))\n",
        "print(\"precision score: \", precision_score(y_val_binary, predictions_knn_binary, average='weighted'))\n",
        "print(\"recall score: \", recall_score(y_val_binary, predictions_knn_binary, average='weighted'))\n",
        "print(\"f1 score: \", f1_score(y_val_binary, predictions_knn_binary,average='weighted'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YRQysYAlyTz"
      },
      "outputs": [],
      "source": [
        "# confusion matrix for KNN binary\n",
        "\n",
        "confusion = confusion_matrix(y_val_binary, predictions_knn_binary)\n",
        "print('Confusion Matrix\\n')\n",
        "print(confusion)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=confusion, display_labels=[\"0\", \"1\"])\n",
        "disp.plot(cmap='Oranges');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8qSUWJ0vuSN"
      },
      "outputs": [],
      "source": [
        "# ROC curve for KNN binary\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "y_score = predictions_knn_binary\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "fpr, tpr, _ = roc_curve(y_val, y_score)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(\n",
        "    fpr,\n",
        "    tpr,\n",
        "    color=\"darkorange\",\n",
        "    lw=lw,\n",
        "    label=\"ROC curve (area = %0.2f)\" % roc_auc,\n",
        ")\n",
        "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Receiver operating characteristic example\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9UD6N0KgRJD"
      },
      "outputs": [],
      "source": [
        "# KNN binary plots \n",
        "\n",
        "neighbors = np.arange(1, 5)\n",
        "neighbors = np.append(neighbors, [50, 100, 2560, 5120])\n",
        "\n",
        "# arrays to store train and test accuracies\n",
        "\n",
        "train_accuracy = np.empty(len(neighbors))\n",
        "test_accuracy = np.empty(len(neighbors))\n",
        "\n",
        "# iterate through different values of k\n",
        "for i, k in enumerate(neighbors):\n",
        "    # initialize model\n",
        "    knn_binary = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "    # train\n",
        "    knn_binary.fit(X_train_binary, y_train_binary)\n",
        "    \n",
        "    # test on training set\n",
        "    train_accuracy[i] = knn_binary.score(X_train_binary, y_train_binary)\n",
        "\n",
        "    # test on testing set\n",
        "    test_accuracy[i] = knn_binary.score(X_val_binary, y_val_binary)\n",
        "\n",
        "# Generate plot\n",
        "plt.title('KNN: varying number of neighbors')\n",
        "plt.plot(neighbors, test_accuracy, label = 'testing accuracy')\n",
        "plt.plot(neighbors, train_accuracy, label = 'training accuracy')\n",
        "plt.legend()\n",
        "plt.xlabel('number of neighbors')\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUDUTStolkfP"
      },
      "outputs": [],
      "source": [
        "# more KNN binary plots\n",
        "\n",
        "neighbors = np.arange(1,21)\n",
        "\n",
        "train_accuracy = np.empty(len(neighbors))\n",
        "test_accuracy = np.empty(len(neighbors))\n",
        "\n",
        "# iterate through different values of k\n",
        "for i, k in enumerate(neighbors):\n",
        "    # Setup a k-NN Classifier with k neighbors: knn\n",
        "    knn_binary = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "    # Fit the classifier to the training data\n",
        "    knn_binary.fit(X_train, y_train)\n",
        "    \n",
        "    #Compute accuracy on the training set\n",
        "    train_accuracy[i] = knn_binary.score(X_train, y_train)\n",
        "\n",
        "    #Compute accuracy on the testing set\n",
        "    val_accuracy[i] = knn_binary.score(X_val, y_val)\n",
        "\n",
        "# Generate plot\n",
        "plt.title('KNN: varying number of neighbors')\n",
        "plt.plot(neighbors, val_accuracy, label = 'Validation Accuracy')\n",
        "plt.plot(neighbors, train_accuracy, label = 'Training Accuracy')\n",
        "plt.legend()\n",
        "plt.xlabel('Number of Neighbors')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP binary"
      ],
      "metadata": {
        "id": "U1w8qqOKNpKB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3d8xbrmJZ4i5"
      },
      "outputs": [],
      "source": [
        "# initialize model\n",
        "mlp_binary = MLPClassifier(hidden_layer_sizes=(10, 5, 4), random_state=1, max_iter= 100)  \n",
        "\n",
        "# train\n",
        "mlp_binary.fit(X_train_binary, y_train_binary)\n",
        "\n",
        "# predict\n",
        "predictions_mlp_binary = mlp_binary.predict(X_val_binary)\n",
        "\n",
        "# model metrics\n",
        "print(\"accuracy score: \", accuracy_score(y_val_binary, predictions_mlp_binary))\n",
        "print(\"precision score: \", precision_score(y_val_binary, predictions_mlp_binary, average='weighted'))\n",
        "print(\"recall score: \", recall_score(y_val_binary, predictions_mlp_binary, average='weighted'))\n",
        "print(\"f1 score: \", f1_score(y_val_binary, predictions_mlp_binary, average='weighted'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVC binary"
      ],
      "metadata": {
        "id": "keYr1l9nNtxk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFQhpd0ZO0GW"
      },
      "outputs": [],
      "source": [
        "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "\n",
        "for kernel_type in kernels:\n",
        "  # initialize model\n",
        "  svc_binary = svm.SVC(kernel = kernel_type)\n",
        "\n",
        "  # train\n",
        "  svc_binary.fit(X_train, y_train_binary)\n",
        "\n",
        "  # predict \n",
        "  predictions_svc_binary = svc_binary.predict(X_val)\n",
        "  \n",
        "  # Print the score on the validation data\n",
        "  print(\"SVC model metrics \", kernel_type)\n",
        "  print(\"accuracy score: \", accuracy_score(y_val_binary, predictions_svc_binary))\n",
        "  print(\"precision score: \", precision_score(y_val_binary, predictions_svc_binary))\n",
        "  print(\"recall score: \", recall_score(y_val_binary, predictions_svc_binary))\n",
        "  print(\"f1 score: \", f1_score(y_val_binary, predictions_svc_binary))\n",
        "  print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes binary"
      ],
      "metadata": {
        "id": "8iWT7MdlOBEe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfBQbtBBO7H0"
      },
      "outputs": [],
      "source": [
        "# initialize model\n",
        "nb_binary = GaussianNB(var_smoothing = 10)\n",
        "\n",
        "# train\n",
        "nb_binary.fit(X_train_binary, y_train_binary)\n",
        "\n",
        "# predict\n",
        "predictions_nb_binary = nb_binary.predict(X_val_binary)\n",
        "print(\"accuracy score: \", accuracy_score(y_val_binary, predictions_nb_binary))\n",
        "print(\"precision score: \", precision_score(y_val_binary, predictions_nb_binary, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_val_binary, predictions_nb_binary, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_val_binary, predictions_nb_binary, average = 'weighted'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN binary"
      ],
      "metadata": {
        "id": "haG_9r3XOEsu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15TYi3rKPBKy"
      },
      "outputs": [],
      "source": [
        "def CNNClassifier(num_classes=2, num_epochs=2, layers=2, dropout=0.25):\n",
        "  def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Reshape((150, 150, 1)))\n",
        "\n",
        "    for i in range(layers):\n",
        "      model.add(Conv2D(150, (3, 3), padding='same'))\n",
        "      model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(150, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(dropout))\n",
        "\n",
        "    # model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "    # model.add(Activation('relu'))\n",
        "    # model.add(Conv2D(64, (3, 3)))\n",
        "    # model.add(Activation('relu'))\n",
        "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    # model.add(Dropout(dropout))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Dense(num_classes))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "  opt = tf.keras.optimizers.legacy.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "  return KerasClassifier(model=create_model, optimizer=opt, \n",
        "                         loss='sparse_categorical_crossentropy', epochs=num_epochs, batch_size=10, \n",
        "                         metrics=['accuracy'])\n",
        "\n",
        "cnn_binary = CNNClassifier(2, 70, 1, 0.25)\n",
        "history = cnn_binary.fit(X=X_train, y=y_train, validation_data=(X_val, y_val))\n",
        "plot_acc(history)\n",
        "\n",
        "predictions_cnn_binary = predictions_cnn_binary.predict(X_val)\n",
        "print(\"accuracy score: \", accuracy_score(y_val, predictions_cnn_binary))\n",
        "print(\"precision score: \", precision_score(y_val, predictions_cnn_binary, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_val, predictions_cnn_binary, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_val, predictions_cnn_binary, average = 'weighted'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MaWEAcmPqBr"
      },
      "outputs": [],
      "source": [
        "# hyperparameter tuning CNN binary\n",
        "\n",
        "from keras.wrappers.scikit_learn import KerasClassifier as KerasClassifier2\n",
        "def create_model(num_classes=2, num_epochs=2, layers=1, dropout=0.15, learning_rate=0.0001, decay=1e-6):\n",
        "    print(\"Dropout: \", dropout)\n",
        "    print(\"Num Epochs: \", num_epochs)\n",
        "    print(\"Learning rate: \", learning_rate)    \n",
        "    print(\"Decay \", decay)    \n",
        "    print(\"Layers \", layers)    \n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Reshape((32, 32, 1)))\n",
        "\n",
        "    for i in range(layers):\n",
        "      model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "      model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(32, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(dropout))\n",
        "\n",
        "    # model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "    # model.add(Activation('relu'))\n",
        "    # model.add(Conv2D(64, (3, 3)))\n",
        "    # model.add(Activation('relu'))\n",
        "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    # model.add(Dropout(dropout))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Dense(num_classes))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    model.compile(optimizer = tf.keras.optimizers.legacy.RMSprop(learning_rate=learning_rate, decay=decay), \n",
        "                  loss = 'sparse_categorical_crossentropy', \n",
        "                  metrics = ['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "CNNClassifier = KerasClassifier2(build_fn=create_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AlexNet binary"
      ],
      "metadata": {
        "id": "LC3zYYHgOOWq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXtNvrX7ecN9"
      },
      "outputs": [],
      "source": [
        "def AlexNetClassifier(num_classes=2, num_epochs=2):\n",
        "  def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Reshape((150, 150, 1)))\n",
        "\n",
        "    model.add(Conv2D(96, 11, strides = 3))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(256, 5))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(MaxPooling2D(2))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(384, 3, padding = 'same'))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(MaxPooling2D(2))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(384, 3, padding = 'same'))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2D(256, 3, padding = 'same'))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(MaxPooling2D(2))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(128))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Dense(2))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "  opt = tf.keras.optimizers.legacy.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "  return KerasClassifier(model=create_model, optimizer=opt, \n",
        "                         loss='sparse_categorical_crossentropy', epochs=num_epochs, batch_size=64, verbose=2, \n",
        "                         metrics=['accuracy'])\n",
        "\n",
        "AlexNet_binary = AlexNetClassifier(2, 70)\n",
        "history = AlexNet_binary.fit(X=X_train, y=y_train, validation_data=(X_val, y_val))\n",
        "plot_acc(history)\n",
        "\n",
        "predictions_AlexNet_binary = AlexNet_binary.predict(X_val)\n",
        "print(\"accuracy score: \", accuracy_score(y_val_binary, predictions_AlexNet_binary))\n",
        "print(\"precision score: \", precision_score(y_val_binary, predictions_AlexNet_binary, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_val_binary, predictions_AlexNet_binary, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_val_binary, predictions_AlexNet_binary, average = 'weighted'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and preparing data - oasis dataset\n",
        "> https://www.oasis-brains.org/#data"
      ],
      "metadata": {
        "id": "mSVRmAoGOaH2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0MaRCtWaJdJ"
      },
      "outputs": [],
      "source": [
        "def label_converter(label):\n",
        "  if label == 0.5:\n",
        "    label = 1\n",
        "  elif label == 1:\n",
        "    label = 2\n",
        "  elif label == 2:\n",
        "    label =3\n",
        "\n",
        "  # 0: non-demented\n",
        "  # 1: very mild demented\n",
        "  # 2: mild demented\n",
        "  # 3: moderate demented\n",
        "  \n",
        "  return label\n",
        "\n",
        "oasis_dataset_dir = 'drive/MyDrive/Extracurriculars/InspiritAI/Deniz Yilmaz/Data/oasis_dataset'\n",
        "\n",
        "# creates label list and image list\n",
        "subject_dirs = glob.glob(oasis_dataset_dir + \"/OAS1*\")\n",
        "oasis_normalized_image_array = []\n",
        "oasis_label_array = []\n",
        "\n",
        "oasis_df = pd.read_csv(oasis_dataset_dir + \"/oasis_cross-sectional_filtered.csv\")\n",
        "\n",
        "# puts stuff in image_list\n",
        "for subject_dir in subject_dirs:\n",
        "  # print(subject_dir)\n",
        "  subject_id = subject_dir.split(\"/\")[7]\n",
        "  # print(subject_id)\n",
        "  label = oasis_df.loc[oasis_df['ID'] == subject_id]['CDR'].item()\n",
        "  # print(label)\n",
        "  label = label_converter(label)\n",
        "  for file in glob.glob(subject_dir + \"/PROCESSED/MPRAGE/T88_111/*masked_gfc_tra_90.gif\"):\n",
        "    image = Image.open(file).resize((32,32))\n",
        "    image = image.rotate(180)\n",
        "    image = image.convert('L') # convert RGB to gray\n",
        "    image = asarray(image)\n",
        "    image = normalize_one_image(image)\n",
        "    image = image.flatten()\n",
        "    # image = black_and_white(image)\n",
        "    oasis_normalized_image_array.append(image)\n",
        "    oasis_label_array.append(label) \n",
        "\n",
        "# creating binary labels\n",
        "oasis_label_binary = oasis_label_array.copy()\n",
        "\n",
        "for idx in range(len(oasis_label_binary)):\n",
        "  if oasis_label_binary[idx] == 3 or oasis_label_binary[idx] == 2:\n",
        "    oasis_label_binary[idx] = 1\n",
        "\n",
        "# multiclass array\n",
        "X_oasis = asarray(oasis_normalized_image_array)\n",
        "y_oasis = asarray(oasis_label_array)\n",
        "\n",
        "# binary array\n",
        "y_oasis_binary = asarray(oasis_label_binary)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "Osx3RdE-O0k9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing oasis dataset"
      ],
      "metadata": {
        "id": "GXIaSBqtO8Uf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zX8zD0OFPpC_"
      },
      "outputs": [],
      "source": [
        "# knn multiclass\n",
        "predictions_knn_multiclass_oasis = knn_multiclass.predict(X_oasis)\n",
        "\n",
        "# knn binary\n",
        "predictions_knn_binary_oasis = knn_binary.predict(X_oasis)\n",
        "\n",
        "# mlp multiclass\n",
        "predictions_mlp_multiclass_oasis = mlp_multiclass.predict(X_oasis)\n",
        "\n",
        "# mlp binary\n",
        "predictions_mlp_binary_oasis = mlp_binary.predict(X_oasis)\n",
        "\n",
        "# svm multiclass\n",
        "predictions_oasis_svc_multiclass = svc_multiclass.predict(X_oasis)\n",
        "\n",
        "# svm binary\n",
        "predictions_oasis_svc_binary = svc_binary.predict(X_oasis)\n",
        "\n",
        "# naive bayes multiclass\n",
        "predictions_oasis_nb_multiclass = nb_multiclass.predict(X_oasis)\n",
        "\n",
        "# naive bayes binary\n",
        "predictions_oasis_nb_binary = nb_binary.predict(X_oasis)\n",
        "\n",
        "# cnn multiclass\n",
        "predictions_oasis_cnn_multiclass = cnn_multiclass.predict(X_oasis)\n",
        "\n",
        "# cnn binary\n",
        "predictions_oasis_cnn_binary = cnn_binary.predict(X_oasis)\n",
        "\n",
        "# alexnet multiclass\n",
        "predictions_oasis_AlexNet_multiclass = AlexNet_multiclass.predict(X_oasis)\n",
        "\n",
        "# alexnet multiclass\n",
        "predictions_oasis_AlexNet_multiclass = AlexNet_multiclass.predict(X_oasis)\n",
        "\n",
        "# Print the metrics on the oasis data\n",
        "print(\"knn multiclass: \")\n",
        "print(\"accuracy score: \", accuracy_score(y_oasis, predictions_knn_multiclass_oasis))\n",
        "print(\"precision score: \", precision_score(y_oasis, predictions_knn_multiclass_oasis, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_oasis, predictions_knn_multiclass_oasis, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_oasis, predictions_knn_multiclass_oasis, average = 'weighted'))\n",
        "print(\"\")\n",
        "print(\"knn binary: \")\n",
        "print(\"accuracy score: \", accuracy_score(y_oasis_binary, predictions_knn_binary_oasis))\n",
        "print(\"precision score: \", precision_score(y_oasis_binary, predictions_knn_binary_oasis, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_oasis_binary, predictions_knn_binary_oasis, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_oasis_binary, predictions_knn_binary_oasis, average = 'weighted'))\n",
        "print(\"\")\n",
        "print(\"mlp multiclass: \")\n",
        "print(\"accuracy score: \", accuracy_score(y_oasis, predictions_mlp_multiclass_oasis))\n",
        "print(\"precision score: \", precision_score(y_oasis, predictions_mlp_multiclass_oasis, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_oasis, predictions_mlp_multiclass_oasis, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_oasis, predictions_mlp_multiclass_oasis, average = 'weighted'))\n",
        "print(\"\")\n",
        "print(\"mlp binary:\")\n",
        "print(\"accuracy score: \", accuracy_score(y_oasis_binary, predictions_mlp_binary_oasis))\n",
        "print(\"precision score: \", precision_score(y_oasis_binary, predictions_mlp_binary_oasis, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_oasis_binary, predictions_mlp_binary_oasis, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_oasis_binary, predictions_mlp_binary_oasis, average = 'weighted'))\n",
        "print(\"\")\n",
        "print(\"svm multiclass\")\n",
        "print(\"accuracy score: \", accuracy_score(y_oasis, predictions_oasis_svc_multiclass))\n",
        "print(\"precision score: \", precision_score(y_oasis, predictions_oasis_svc_multiclass, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_oasis, predictions_oasis_svc_multiclass, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_oasis, predictions_oasis_svc_multiclass, average = 'weighted'))\n",
        "print(\"\")\n",
        "print(\"svm binary\")\n",
        "print(\"accuracy score: \", accuracy_score(y_oasis_binary, predictions_oasis_svc_binary))\n",
        "print(\"precision score: \", precision_score(y_oasis_binary, predictions_oasis_svc_binary, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_oasis_binary, predictions_oasis_svc_binary, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_oasis_binary, predictions_oasis_svc_binary, average = 'weighted'))\n",
        "print(\"\")\n",
        "print(\"naive bayes mutliclass\")\n",
        "print(\"accuracy score: \", accuracy_score(y_oasis, predictions_oasis_nb_multiclass))\n",
        "print(\"precision score: \", precision_score(y_oasis, predictions_oasis_nb_multiclass, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_oasis, predictions_oasis_nb_multiclass, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_oasis, predictions_oasis_nb_multiclass, average = 'weighted'))\n",
        "print(\"\")\n",
        "print(\"naive bayes binary\")\n",
        "print(\"accuracy score: \", accuracy_score(y_oasis_binary, predictions_oasis_nb_binary))\n",
        "print(\"precision score: \", precision_score(y_oasis_binary, predictions_oasis_nb_binary, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_oasis_binary, predictions_oasis_nb_binary, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_oasis_binary, predictions_oasis_nb_binary, average = 'weighted'))\n",
        "print(\"\")\n",
        "print(\"cnn multiclass\")\n",
        "print(\"accuracy score: \", accuracy_score(y_oasis, predictions_oasis_cnn_multiclass))\n",
        "print(\"precision score: \", precision_score(y_oasis, predictions_oasis_cnn_multiclass, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_oasis, predictions_oasis_cnn_multiclass, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_oasis, predictions_oasis_cnn_multiclass, average = 'weighted'))\n",
        "print(\"\")\n",
        "print(\"cnn binary\")\n",
        "print(\"accuracy score: \", accuracy_score(y_oasis_binary, predictions_oasis_cnn_binary))\n",
        "print(\"precision score: \", precision_score(y_oasis_binary, predictions_oasis_cnn_binary, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_oasis_binary, predictions_oasis_cnn_binary, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_oasis_binary, predictions_oasis_cnn_binary, average = 'weighted'))\n",
        "print(\"\")\n",
        "print(\"alexnet multiclass\")\n",
        "print(\"accuracy score: \", accuracy_score(y_oasis, predictions_oasis_AlexNet_multiclass))\n",
        "print(\"precision score: \", precision_score(y_oasis, predictions_oasis_AlexNet_multiclass, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_oasis, predictions_oasis_AlexNet_multiclass, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_oasis, predictions_oasis_AlexNet_multiclass, average = 'weighted'))\n",
        "print(\"\")\n",
        "print(\"alexnet binary\")\n",
        "print(\"accuracy score: \", accuracy_score(y_oasis_binary, predictions_oasis_AlexNet_binary))\n",
        "print(\"precision score: \", precision_score(y_oasis_binary, predictions_oasis_AlexNet_binary, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_oasis_binary, predictions_oasis_AlexNet_binary, average = 'weighted'))\n",
        "3print(\"f1 score: \", f1_score(y_oasis_binary, predictions_oasis_AlexNet_binary, average = 'weighted'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing kaggle dataset"
      ],
      "metadata": {
        "id": "cB0XkfjfPSst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# knn multiclass\n",
        "predictions_knn_multiclass = knn_multiclass.predict(X_test)\n",
        "\n",
        "# knn binary\n",
        "predictions_knn_binary = knn_binary.predict(X_test)\n",
        "\n",
        "# mlp multiclass\n",
        "predictions_mlp_multiclass = mlp_multiclass.predict(X_test)\n",
        "\n",
        "# mlp binary\n",
        "predictions_mlp_binary = mlp_binary.predict(X_test)\n",
        "\n",
        "# svm multiclass\n",
        "predictions_svc_multiclass = svc_multiclass.predict(X_test)\n",
        "\n",
        "# svm binary\n",
        "predictions_svc_binary = svc_binary.predict(X_test)\n",
        "\n",
        "# naive bayes multiclass\n",
        "predictions_nb_multiclass = nb_multiclass.predict(X_test)\n",
        "\n",
        "# naive bayes binary\n",
        "predictions_nb_binary = nb_binary.predict(X_test)\n",
        "\n",
        "# cnn multiclass\n",
        "predictions_cnn_multiclass = cnn_multiclass.predict(X_test)\n",
        "\n",
        "# cnn binary\n",
        "predictions_cnn_binary = cnn_binary.predict(X_test)\n",
        "\n",
        "# alexnet multiclass\n",
        "predictions_AlexNet_multiclass = AlexNet_multiclass.predict(X_test)\n",
        "\n",
        "# alexnet multiclass\n",
        "predictions_AlexNet_multiclass = AlexNet_multiclass.predict(X_test)\n",
        "\n",
        "# Print the metrics on the kaggle data\n",
        "print(\"knn multiclass: \")\n",
        "print(\"accuracy score: \", accuracy_score(y_test, predictions_knn_multiclass))\n",
        "print(\"precision score: \", precision_score(y_test, predictions_knn_multiclass, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_test, predictions_knn_multiclass, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_test, predictions_knn_multiclass, average = 'weighted'))\n",
        "print(\"\")\n",
        "print(\"knn binary: \")\n",
        "print(\"accuracy score: \", accuracy_score(y_test_binary, predictions_knn_binary))\n",
        "print(\"precision score: \", precision_score(y_test_binary, predictions_knn_binary, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_test_binary, predictions_knn_binary, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_test_binary, predictions_knn_binary, average = 'weighted'))\n",
        "print(\"\")\n",
        "print(\"mlp multiclass: \")\n",
        "print(\"accuracy score: \", accuracy_score(y_test, predictions_mlp_multiclass))\n",
        "print(\"precision score: \", precision_score(y_test, predictions_mlp_multiclass, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_test, predictions_mlp_multiclass, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_test, predictions_mlp_multiclass, average = 'weighted'))\n",
        "print(\"\")\n",
        "print(\"mlp binary:\")\n",
        "print(\"accuracy score: \", accuracy_score(y_test_binary, predictions_mlp_binary))\n",
        "print(\"precision score: \", precision_score(y_test_binary, predictions_mlp_binary, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_test_binary, predictions_mlp_binary, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_test_binary, predictions_mlp_binary, average = 'weighted'))\n",
        "print(\"\")\n",
        "print(\"svm multiclass\")\n",
        "print(\"accuracy score: \", accuracy_score(y_test, predictions_svc_multiclass))\n",
        "print(\"precision score: \", precision_score(y_test, predictions_svc_multiclass, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_test, predictions_svc_multiclass, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_test, predictions_svc_multiclass, average = 'weighted'))\n",
        "print(\"\")\n",
        "print(\"svm binary\")\n",
        "print(\"accuracy score: \", accuracy_score(y_test_binary, predictions_svc_binary))\n",
        "print(\"precision score: \", precision_score(y_test_binary, predictions_svc_binary, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_test_binary, predictions_svc_binary, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_test_binary, predictions_svc_binary, average = 'weighted'))\n",
        "print(\"\")\n",
        "print(\"naive bayes mutliclass\")\n",
        "print(\"accuracy score: \", accuracy_score(y_test, predictions_nb_multiclass))\n",
        "print(\"precision score: \", precision_score(y_test, predictions_nb_multiclass, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_test, predictions_nb_multiclass, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_test, predictions_nb_multiclass, average = 'weighted'))\n",
        "print(\"\")\n",
        "print(\"naive bayes binary\")\n",
        "print(\"accuracy score: \", accuracy_score(y_test_binary, predictions_nb_binary))\n",
        "print(\"precision score: \", precision_score(y_test_binary, predictions_nb_binary, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_test_binary, predictions_nb_binary, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_test_binary, predictions_nb_binary, average = 'weighted'))\n",
        "print(\"\")\n",
        "print(\"cnn multiclass\")\n",
        "print(\"accuracy score: \", accuracy_score(y_test, predictions_cnn_multiclass))\n",
        "print(\"precision score: \", precision_score(y_test, predictions_cnn_multiclass, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_test, predictions_cnn_multiclass, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_test, predictions_cnn_multiclass, average = 'weighted'))\n",
        "print(\"\")\n",
        "print(\"cnn binary\")\n",
        "print(\"accuracy score: \", accuracy_score(y_test_binary, predictions_cnn_binary))\n",
        "print(\"precision score: \", precision_score(y_test_binary, predictions_cnn_binary, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_test_binary, predictions_cnn_binary, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_test_binary, predictions_cnn_binary, average = 'weighted'))\n",
        "print(\"\")\n",
        "print(\"alexnet multiclass\")\n",
        "print(\"accuracy score: \", accuracy_score(y_test, predictions_AlexNet_multiclass))\n",
        "print(\"precision score: \", precision_score(y_test, predictions_AlexNet_multiclass, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_test, predictions_AlexNet_multiclass, average = 'weighted'))\n",
        "print(\"f1 score: \", f1_score(y_test, predictions_AlexNet_multiclass, average = 'weighted'))\n",
        "print(\"\")\n",
        "print(\"alexnet binary\")\n",
        "print(\"accuracy score: \", accuracy_score(y_test_binary, predictions_AlexNet_binary))\n",
        "print(\"precision score: \", precision_score(y_test_binary, predictions_AlexNet_binary, average = 'weighted'))\n",
        "print(\"recall score: \", recall_score(y_test_binary, predictions_AlexNet_binary, average = 'weighted'))\n",
        "3print(\"f1 score: \", f1_score(y_test_binary, predictions_AlexNet_binary, average = 'weighted'))"
      ],
      "metadata": {
        "id": "_6GWsz8tRzrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SHAP\n",
        "SHAP (SHapley Additive exPlanations) is an approach for explainable machine learning based in game theory. By computing Shapley values for each pixel, the most important regions of the MRI scans for classification are revealed. \n",
        "\n",
        "In the cells below, SHAP was used to explain the results of the binary CNN classifier. "
      ],
      "metadata": {
        "id": "VujhJD75PGFN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGlvZD2kRPbB"
      },
      "outputs": [],
      "source": [
        "# single image\n",
        "\n",
        "# get prediction\n",
        "def f(x):\n",
        "    return cnn_binary.predict(x.reshape(x.shape[0],1024))\n",
        "\n",
        "# define a masker \n",
        "masker = shap.maskers.Image(\"inpaint_telea\", (32,32,1))\n",
        "\n",
        "# create an explainer\n",
        "explainer = shap.Explainer(f, masker)\n",
        "\n",
        "# getting shap values\n",
        "shap_values = explainer(X_train[1].reshape(1,32,32,1), max_evals=500)\n",
        "shap_values.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZUpT6qtReJM"
      },
      "outputs": [],
      "source": [
        "# overlaying multiple images\n",
        "\n",
        "# get prediction\n",
        "def f(x):\n",
        "    return cnn_binary.predict(x.reshape(x.shape[0],1024))\n",
        "\n",
        "# define a masker \n",
        "masker = shap.maskers.Image(\"inpaint_telea\", (32,32,1))\n",
        "\n",
        "# create an explainer\n",
        "explainer = shap.Explainer(f, masker)\n",
        "\n",
        "# getting shap values\n",
        "X_shap = X_train[0:10]\n",
        "num_images = X_shap.shape[0]\n",
        "X_shap = X_shap.reshape(num_images,32,32,1)\n",
        "shap_values = explainer(X_shap, max_evals=500)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}